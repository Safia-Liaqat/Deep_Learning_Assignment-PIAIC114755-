{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers_Recognition(PIAIC114755).ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safia211/Deep_Learning_Assignment-PIAIC114755-/blob/master/Flowers_Recognition(PIAIC114755).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXgJ6uT1NydQ"
      },
      "source": [
        "Assignment: Flowers Recognition <br>\n",
        "Dataset Description:<br>\n",
        "\n",
        "This dataset contains 4242 images of flowers.<br>\n",
        "The data collection is based on the data flicr, google images, yandex images.<br>\n",
        "You can use this datastet to recognize plants from the photo.<br>\n",
        "\n",
        "Attribute Information:<br>\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
        "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
        "This is a Multiclass Classification Problem.<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7vy-ktuOKJH"
      },
      "source": [
        "WORKFLOW : <br>\n",
        "Load Data <br>\n",
        "Split into 60 and 40 ratio.<br>\n",
        "Encode labels.<br>\n",
        "Create Model<br>\n",
        "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
        "Train the Model.<br>\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
        "Prediction should be > 85%<br>\n",
        "Evaluation Step<br>\n",
        "Prediction<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3Bg5qfPRic"
      },
      "source": [
        "Data : <br>\n",
        "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTtg3WuGTA1o"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "import os\n",
        "from os.path import join\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMx-7wNuHBQu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe4cHR0THP5G"
      },
      "source": [
        "# data = \"/content/drive/MyDrive/flowers/flowers\"\n",
        "# folders = os.listdir(data)\n",
        "# print(folders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcgVpzDLPtAb"
      },
      "source": [
        "# Loading Data And Defining Features And Labels\n",
        "directory = Path(\"/content/drive/MyDrive/flowers/flowers\")\n",
        "\n",
        "image_names = []\n",
        "data_images = []\n",
        "labels = []\n",
        "\n",
        "# Iterating Over Directory To Extract Sub Directories\n",
        "for dir in directory.iterdir():\n",
        "  image_names.append(dir.name)\n",
        "  print(dir.name)\n",
        "# Iterating Over Sub Directories To Extract Lables\n",
        "  for imgpath in dir.iterdir():\n",
        "    if imgpath.name.endswith(\"jpg\"):\n",
        "      labels.append(dir.name)\n",
        "      imgarr = cv2.imread(str(imgpath), cv2.IMREAD_GRAYSCALE)\n",
        "      imgarr = cv2.resize(imgarr, (150,150))\n",
        "      data_images.append(imgarr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTbsQGT2Hgdt"
      },
      "source": [
        "# image_names = [] #flowers\n",
        "# labels = []\n",
        "# data_images = [] #features\n",
        "\n",
        "\n",
        "# size = 150,150\n",
        "\n",
        "# for folder in folders:\n",
        "#     for file in os.listdir(os.path.join(data,folder)):\n",
        "#         if file.endswith(\"jpg\"):\n",
        "#             image_names.append(os.path.join(data,folder,file))\n",
        "#             labels.append(folder)\n",
        "#             img = cv2.imread(os.path.join(data,folder,file),cv2.IMREAD_GRAYSCALE)\n",
        "#             im = cv2.resize(img,size)\n",
        "#             data_images.append(im)\n",
        "#         else:\n",
        "#             continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq5M5N3OyIpo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVCjHSU4H1yP"
      },
      "source": [
        "# label_dummies = pd.get_dummies(labels)\n",
        "# labels =  label_dummies.values.argmax(1)\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "labels = LabelEncoder().fit_transform(labels)\n",
        "labels=to_categorical(labels) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDomXtB4yp8N"
      },
      "source": [
        "#labels=np.asarray(labels).astype(\"float32\")\n",
        "#data = np.asarray(data_images).astype(\"float32\")/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5oX13lcyuzM"
      },
      "source": [
        "#print(f\"Shape of images is :{data.shape}\")\n",
        "#print(f\"Shape of labels is :{labels.shap\n",
        "image_names=np.asarray(image_names)\n",
        "image_names.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QgNXLxOOL3L"
      },
      "source": [
        "data = np.asarray(data_images).reshape(4328,150*150)\n",
        "data = data.astype(\"float32\")/255.0\n",
        "#labels = np.asarray(labels).astype(\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo5n5Ih_O8tq"
      },
      "source": [
        "data.shape\n",
        "data.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMHVsmI-yxxA"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(data,labels,test_size=.40,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJo3XdvZy7lX"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLM9_nHbzGsB"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtihsfANQZkq"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haSeIl3ARoxH"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fJMEqV1Ro_s"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tCcrkDCRpMU"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6W7Sh-2SVbE"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB12EblmSVvQ"
      },
      "source": [
        "# y_train=to_categorical(y_train)\n",
        "# y_test=to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI-pV845zMyp"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras import losses,optimizers,regularizers\n",
        "network =Sequential()\n",
        "network.add(Dense(256,kernel_regularizer=regularizers.l2(0.001),activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
        "#network.add(Dropout(0.2))\n",
        "network.add(Dense(128,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
        "network.add(Dense(64,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
        "#network.add(Dropout(0.2))\n",
        "network.add(Dense(32,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
        "#network.add(Dropout(0.2))\n",
        "network.add(Dense(5,activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdmwvlezbLI"
      },
      "source": [
        "#network.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdOw1dZRSF2H"
      },
      "source": [
        "network.compile(loss='categorical_crossentropy',optimizer='rmsPROP',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw8JL2-azoDi"
      },
      "source": [
        "batch_size = 20\n",
        "epochs = 500\n",
        "history=network.fit(X_train, y_train,batch_size=batch_size,epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rs111Og0PBy"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "[u'accuracy', u'loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jncnFKF60R0z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_accuracy = history_dict['accuracy']\n",
        "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "plt.plot(epochs, loss_values, 'r', label='loss')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='accuracy')\n",
        "plt.title('loss and accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX2SuLC10oCQ"
      },
      "source": [
        "network.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntXme5Nn0qa5"
      },
      "source": [
        "pred = network.predict_classes(X_test[:10])\n",
        "for i in range(len(pred)):\n",
        "    print(pred[i],'==>',y_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DAHTUA0yZw"
      },
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1, 2, 1 )\n",
        "plt.hist(y_test[:10])\n",
        "plt.xlabel('original target value')\n",
        "plt.ylabel('count')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(pred)\n",
        "plt.xlabel('aggregated target value')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}